# Multimodal Disease Classification Framework

A disease-agnostic multimodal deep learning framework that predicts diseases from CT images enhanced with minimal lab values (CRP, WBC, Hb).

## ğŸ¯ Project Overview

This framework demonstrates that combining CT imaging with just **three key lab biomarkers** can effectively classify multiple disease categories:

| Class | Description |
|-------|-------------|
| 0 | Normal |
| 1 | Tumor |
| 2 | Infection |
| 3 | Inflammatory |

### Why This Approach?

Traditional systems require:
- One model per disease
- Heavy clinical inputs
- Not scalable

**Our system:**
- One unified model
- Multiple disease classes  
- Minimal lab data (only 3 values!)
- CT-based imaging

## ğŸ“ Project Structure

```
disease_classifier/
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ main.py                   # Main experiment runner
â”œâ”€â”€ train.py                  # Training script
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py           # Dataset classes
â”‚   â””â”€â”€ lab_generator.py     # Synthetic lab value generator
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cnn_encoder.py       # CNN for CT images
â”‚   â”œâ”€â”€ lab_encoder.py       # MLP for lab values
â”‚   â””â”€â”€ fusion_model.py      # Multimodal fusion
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py            # Logging utilities
â”‚   â””â”€â”€ metrics.py           # Evaluation metrics
â”œâ”€â”€ saved_models/            # Trained model checkpoints
â”œâ”€â”€ results/                 # Experiment results
â””â”€â”€ logs/                    # Training logs
```

## ğŸ”¬ Lab Values and Disease Correlation

| Disease Type | CRP | WBC | Hb |
|-------------|-----|-----|-----|
| Normal | Low | Normal | Normal |
| Tumor | Moderate â†‘ | Slight â†‘ | â†“ |
| Infection | High â†‘â†‘ | High â†‘â†‘ | Slight â†“ |
| Inflammatory | High â†‘ | Normal/â†‘ | Normal |

**Key insight:** Same CT patterns may overlap, but labs provide contextual disambiguation.

## ğŸ—ï¸ Architecture

```
CT Image
   â”‚
CNN Encoder (ResNet18/Simple CNN)
   â”‚
Image Feature Vector (512-dim)
   â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                       â”‚
CRP, WBC, Hb               â”‚
   â”‚                       â”‚
MLP Encoder                â”‚
   â”‚                       â”‚
Lab Feature Vector (64-dim)â”‚
   â””â”€â”€â”€â”€â”€â”€ Fusion Layer â”€â”€â”€â”˜
               â”‚
        Fully Connected
               â”‚
        Softmax (4 classes)
```

### Fusion Methods
- **Concat**: Simple concatenation
- **Gated**: Learned weighting of modalities
- **Attention**: Cross-attention mechanism

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install torch torchvision numpy scikit-learn matplotlib tqdm pillow
```

### 2. Run Quick Test

```bash
cd disease_classifier
python main.py --mode quick_test
```

### 3. Run Full Experiments

```bash
python main.py --mode full
```

This runs:
1. **Baseline 1**: CT-only model
2. **Baseline 2**: Lab-only model
3. **Proposed**: Fusion model (concat)
4. **Proposed**: Fusion model (gated)

### 4. Train Custom Model

```bash
python train.py --model_type fusion --fusion_method concat --epochs 50
```

**Options:**
- `--model_type`: `fusion`, `image_only`, `lab_only`
- `--fusion_method`: `concat`, `gated`, `attention`
- `--epochs`: Number of training epochs
- `--batch_size`: Batch size
- `--lr`: Learning rate

## ğŸ“Š Experiments

### Baselines
- **CT-only**: Uses only image features
- **Lab-only**: Uses only CRP, WBC, Hb

### Proposed Models
- **Fusion (concat)**: Concatenates image and lab features
- **Fusion (gated)**: Learns to weight modalities

### Metrics Computed
- Accuracy
- Precision (per-class and macro)
- Recall (per-class and macro)
- F1-Score
- ROC-AUC (multi-class)
- Confusion Matrix

## ğŸ“ˆ Expected Results

With synthetic data, the fusion model should outperform single-modality baselines, demonstrating the complementary value of lab values.

## ğŸ”§ Using Real Data

To use real CT images instead of synthetic data:

1. Organize images in folders:
```
data/
â”œâ”€â”€ Normal/
â”‚   â”œâ”€â”€ img001.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Tumor/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Infection/
â”‚   â””â”€â”€ ...
â””â”€â”€ Inflammatory/
    â””â”€â”€ ...
```

2. Modify the data loading:
```python
train_loader, val_loader, test_loader, normalizer = create_data_loaders(
    data_dir='path/to/data',
    use_synthetic=False
)
```

## ğŸ“ Citation

If you use this framework, please cite:

```
@article{multimodal_disease_2024,
  title={Disease-Agnostic Multimodal Framework for CT-based Disease Classification with Minimal Lab Values},
  author={Your Name},
  year={2024}
}
```

## ğŸ“„ License

MIT License
